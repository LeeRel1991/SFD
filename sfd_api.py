#!/usr/bin/env python
# encoding: utf-8

"""
@version: ??
@author: r.li
@license: Apache Licence 
@contact: r.li@bmi-tech.com
@site: 
@software: PyCharm
@file: sfd_api.py
@time: 18-5-21 下午5:55
"""
import cv2
import time

from sfd import SFD
import numpy as np
import os


def iou(bbox1, bbox2):
    """
    Calculates the intersection-over-union of two bounding boxes.

    Args:
        bbox1 (numpy.array, list of floats): bounding box in format x1,y1,x2,y2.
        bbox2 (numpy.array, list of floats): bounding box in format x1,y1,x2,y2.

    Returns:
        int: intersection-over-onion of bbox1, bbox2
    """

    bbox1 = [float(x) for x in bbox1]
    bbox2 = [float(x) for x in bbox2]

    (x0_1, y0_1, x1_1, y1_1) = bbox1
    (x0_2, y0_2, x1_2, y1_2) = bbox2

    # get the overlap rectangle
    overlap_x0 = max(x0_1, x0_2)
    overlap_y0 = max(y0_1, y0_2)
    overlap_x1 = min(x1_1, x1_2)
    overlap_y1 = min(y1_1, y1_2)

    # check if there is an overlap
    if overlap_x1 - overlap_x0 <= 0 or overlap_y1 - overlap_y0 <= 0:
        return 0

    # if yes, calculate the ratio of the overlap to each ROI size and the unified size
    size_1 = (x1_1 - x0_1) * (y1_1 - y0_1)
    size_2 = (x1_2 - x0_2) * (y1_2 - y0_2)
    size_intersection = (overlap_x1 - overlap_x0) * (overlap_y1 - overlap_y0)
    size_union = size_1 + size_2 - size_intersection

    return size_intersection / size_union


class IOUTracker:
    def __init__(self, sigma_l, sigma_h, sigma_iou, t_min):
        self.sigma_l = sigma_l
        self.sigma_h = sigma_h
        self.sigma_iou = sigma_iou
        self.t_min = t_min

        self.tracks_active = []
        self.tracks_finished = []
        self.last_nonupt_tracks = []
        self.total_num = 0

    def track(self, new_detections, frame_num):
        tic = time.time()
        # apply low threshold to detections
        dets = [det for det in new_detections if det['score'] >= self.sigma_l]

        updated_tracks = []

        tmp = self.tracks_active+self.last_nonupt_tracks
        self.last_nonupt_tracks = []
        for track in self.tracks_active:
            if len(dets) > 0:
                # get det with highest iou
                best_match = max(dets, key=lambda x: iou(track['bboxes'][-1], x['bbox']))
                if iou(track['bboxes'][-1], best_match['bbox']) >= self.sigma_iou:
                    track['bboxes'].append(best_match['bbox'])
                    track['max_score'] = max(track['max_score'], best_match['score'])

                    updated_tracks.append(track)

                    # remove from best matching detection from detections
                    del dets[dets.index(best_match)]

            # if track was not updated
            if len(updated_tracks) == 0 or track is not updated_tracks[-1]:
                # finish track when the conditions are met
                if track['max_score'] >= self.sigma_h and len(track['bboxes']) >= self.t_min:
                    print("warning: ID:{} bbox might be disappear.".format(track['ID']))
                    print("start_frame: {}, frame_num: {}\n".format(track['start_frame'], len(track['bboxes'])))
                    self.last_nonupt_tracks.append(track)

        # create new tracks

        new_tracks = [{'bboxes': [det['bbox']], 'max_score': det['score'], 'start_frame': frame_num, 'ID': i + self.total_num} for i, det in enumerate(dets, start=1)]
        self.tracks_active = updated_tracks + new_tracks
        self.total_num += len(new_tracks)
        toc = time.time()
        print("track time: ", toc - tic)
        return self.tracks_active


def track_iou(detections, sigma_l, sigma_h, sigma_iou, t_min):
    """
    Simple IOU based tracker.
    See "High-Speed Tracking-by-Detection Without Using Image Information by E. Bochinski, V. Eiselein, T. Sikora" for
    more information.

    Args:
         detections (list): list of detections per frame, usually generated by util.load_mot
         sigma_l (float): low detection threshold.
         sigma_h (float): high detection threshold.
         sigma_iou (float): IOU threshold.
         t_min (float): minimum track length in frames.

    Returns:
        list: list of tracks.
    """

    for frame_num, detections_frame in enumerate(detections, start=1):
        # apply low threshold to detections
        dets = [det for det in detections_frame if det['score'] >= sigma_l]

        updated_tracks = []
        for track in tracks_active:
            if len(dets) > 0:
                # get det with highest iou
                best_match = max(dets, key=lambda x: iou(track['bboxes'][-1], x['bbox']))
                if iou(track['bboxes'][-1], best_match['bbox']) >= sigma_iou:
                    track['bboxes'].append(best_match['bbox'])
                    track['max_score'] = max(track['max_score'], best_match['score'])

                    updated_tracks.append(track)

                    # remove from best matching detection from detections
                    del dets[dets.index(best_match)]

            # if track was not updated
            if len(updated_tracks) == 0 or track is not updated_tracks[-1]:
                # finish track when the conditions are met
                if track['max_score'] >= sigma_h and len(track['bboxes']) >= t_min:
                    tracks_finished.append(track)

        # create new tracks
        new_tracks = [{'bboxes': [det['bbox']], 'max_score': det['score'], 'start_frame': frame_num} for det in dets]
        tracks_active = updated_tracks + new_tracks

    # finish all remaining active tracks
    tracks_finished += [track for track in tracks_active
                        if track['max_score'] >= sigma_h and len(track['bboxes']) >= t_min]

    return tracks_finished


class SDF_API:
    def __init__(self, model_path):
        self.detector = SFD(os.path.join(model_path, "SFD_deploy.prototxt"),
                            os.path.join(model_path, "SFD_weights.caffemodel"))
        self.dets = None
        self.img = None
        self.pid = 0

    def draw_detect_result(self):
        for line in self.dets:
            score, x1, y1, x2, y2 = line
            # print("bbox2 ", x1, y1, x2, y2)
            cv2.rectangle(self.img, (x1, y1), (x2, y2), (0, 255, 0), 4)
            cv2.putText(self.img, "score: {:.2f}, size: {:.2f} x {:.2f}".format(score, x2 - x1, y2 - y1), (x1, y1),
                        cv2.FONT_HERSHEY_PLAIN, 1.2, (255, 0, 0), 2)

        cv2.imshow("out", cv2.cvtColor(self.img.astype(np.uint8), cv2.COLOR_RGB2BGR))
        cv2.waitKey(1)

    def process_image(self, image_file):
        pass

    def process_video(self, video_file):
        cap = cv2.VideoCapture()
        r = cap.open(video_file)

        # fp = open("sfd_detects.txt", 'w')

        if not r:
            return

        while True:
            r, image = cap.read()
            if not r:
                break
            self.img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            self.dets = self.detector.detect(self.img)
            self.draw_detect_result()

            # 将检测结果按"frameId faceCnt x1 y1 w h x1 y1 w h ... "的格式写入文档
            # bboxs = self.dets[:, 1:]
            # bboxs[:, 2:] = bboxs[:, 2:] - bboxs[:, 0:2]
            #
            # rm_idx = [id for id, x in enumerate(bboxs) if x[2] <= 0 or x[3] <= 0]
            # bboxs = np.delete(bboxs, rm_idx, 0)
            # out_str = "{} {}".format(self.pid, bboxs.shape[0])
            # if bboxs.shape[0] > 0:
            #     out_str += " " + " ".join(str(int(v)) for bbox in bboxs for v in bbox)
            # out_str += "\n"
            # print(out_str)
            # fp.write(out_str)

            self.pid += 1

        # fp.close()

    def detect_with_tracker(self, video_file):
        cap = cv2.VideoCapture()
        r = cap.open(video_file)

        tracker = IOUTracker(0, 0.5, 0.3, 2)
        if not r:
            return

        while True:
            r, image = cap.read()
            if not r:
                break

            self.pid += 1
            self.img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            self.dets = self.detector.detect(self.img)

            new_dets = []
            for line in self.dets:
                score, x1, y1, x2, y2 = line
                new_dets.append({'bbox': (x1, y1, x2, y2), 'score': score})

            tracks = tracker.track(new_dets, self.pid)
            self.draw_track_result(tracks)

    def draw_track_result(self, tracks):
        for track in tracks:
            x1, y1, x2, y2 = track['bboxes'][-1]

            # print("bbox2 ", x1, y1, x2, y2)
            cv2.rectangle(self.img, (x1, y1), (x2, y2), (0, 255, 0), 4)
            cv2.putText(self.img, "ID: {}, score: {:.2f}, ".format(track['ID'], track['max_score']), (x1, y1),
                    cv2.FONT_HERSHEY_PLAIN, 1.2, (255, 0, 0), 2)

        cv2.imshow("out", cv2.cvtColor(self.img.astype(np.uint8), cv2.COLOR_RGB2BGR))
        cv2.waitKey(1)

if __name__ == '__main__':
    api = SDF_API("./models/VGGNet/WIDER_FACE/SFD_trained")
    # api.process_video("/media/lirui/Program/Datas/Videos/2018-04-10-3member.mp4")
    api.detect_with_tracker("/media/lirui/Program/Datas/Videos/2018-04-10-3member.mp4")